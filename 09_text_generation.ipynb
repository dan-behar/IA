{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d39ad6b081a14b05868a011f87819399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f9b4e18295e4acdb62778d85f8ab9c3",
              "IPY_MODEL_728b096756f042bf98a09d0feef343fe",
              "IPY_MODEL_c74e37d7ef524cd68a5005c6f53e84e5"
            ],
            "layout": "IPY_MODEL_6a4b4a3d87604c32a0b557dd73b4fc31"
          }
        },
        "8f9b4e18295e4acdb62778d85f8ab9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef3752f9cca47d68afc9f061a2b5dda",
            "placeholder": "​",
            "style": "IPY_MODEL_743fd462a25a4bc2a7bd3572d6d6e58b",
            "value": "Downloading: 100%"
          }
        },
        "728b096756f042bf98a09d0feef343fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8e5b06088648d791d48d02b667e849",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b4aaa1e9b0e43f48ccbdb3642f90b45",
            "value": 665
          }
        },
        "c74e37d7ef524cd68a5005c6f53e84e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac216e9aa2ce4219acf8a91fac050e01",
            "placeholder": "​",
            "style": "IPY_MODEL_3e2faa7f70cf4dbe910610ee7b216d5e",
            "value": " 665/665 [00:00&lt;00:00, 5.46kB/s]"
          }
        },
        "6a4b4a3d87604c32a0b557dd73b4fc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef3752f9cca47d68afc9f061a2b5dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "743fd462a25a4bc2a7bd3572d6d6e58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8e5b06088648d791d48d02b667e849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4aaa1e9b0e43f48ccbdb3642f90b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac216e9aa2ce4219acf8a91fac050e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2faa7f70cf4dbe910610ee7b216d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40eb2ebcb0347beb81ec289e63d6185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6968962ec55d42df8b893a63206c733c",
              "IPY_MODEL_6d130b10151b44a991debbd23cffd40b",
              "IPY_MODEL_84e8eb32124241b5b3b3a4ec1a07f12e"
            ],
            "layout": "IPY_MODEL_7ca96234db33425c926eef9ee1284be0"
          }
        },
        "6968962ec55d42df8b893a63206c733c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74bcd8f11f1f4eaf9679bb70162d975d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d5ea266c15545d1b3db5a4fc11e6b68",
            "value": "Downloading: 100%"
          }
        },
        "6d130b10151b44a991debbd23cffd40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ff78bfe2de4363a07d179e1210a52c",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b58cb082e9c47f69c5d19d627273231",
            "value": 1042301
          }
        },
        "84e8eb32124241b5b3b3a4ec1a07f12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e480b02d1eab48c1a6ea3211936fa7a7",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0457a7fb354f008ad51ca388e9e4f2",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "7ca96234db33425c926eef9ee1284be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74bcd8f11f1f4eaf9679bb70162d975d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5ea266c15545d1b3db5a4fc11e6b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ff78bfe2de4363a07d179e1210a52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b58cb082e9c47f69c5d19d627273231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e480b02d1eab48c1a6ea3211936fa7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0457a7fb354f008ad51ca388e9e4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83ed795fcba4016a54297088d67ee6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb0564ae7eb6436381f83e2461fdc02b",
              "IPY_MODEL_99c11a811f7f498885f00745fbc10bdb",
              "IPY_MODEL_cb4eb3618ab24acdb0d7f9507deb6744"
            ],
            "layout": "IPY_MODEL_4e13b57a0c374c3da782df32e92d62f9"
          }
        },
        "fb0564ae7eb6436381f83e2461fdc02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c17192ffa56407c9bf2eb43612c3c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_eef8ceed7f5140deace8a302cc704a68",
            "value": "Downloading: 100%"
          }
        },
        "99c11a811f7f498885f00745fbc10bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f5b6fb4aaac46008627390c01221bd0",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6669588ba4eb484da1e952f503e98ba4",
            "value": 456318
          }
        },
        "cb4eb3618ab24acdb0d7f9507deb6744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9616f3c02e1b405baf570227acd63c94",
            "placeholder": "​",
            "style": "IPY_MODEL_5c43c5011672449da95099d0ee961123",
            "value": " 446k/446k [00:00&lt;00:00, 1.01MB/s]"
          }
        },
        "4e13b57a0c374c3da782df32e92d62f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c17192ffa56407c9bf2eb43612c3c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef8ceed7f5140deace8a302cc704a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5b6fb4aaac46008627390c01221bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6669588ba4eb484da1e952f503e98ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9616f3c02e1b405baf570227acd63c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c43c5011672449da95099d0ee961123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f244838b19a249c494ae443a4f147491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfb7ae726d324c978990368734de4a0b",
              "IPY_MODEL_dad6e8b4c2a042e89b7c2205d2a81d0f",
              "IPY_MODEL_b4d929effc8b41d389daf3becac2fa90"
            ],
            "layout": "IPY_MODEL_c1af9a634090418f8d0e4c4d5b262fb2"
          }
        },
        "cfb7ae726d324c978990368734de4a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc4a5b5077b1443cb2373f1b9cd85af6",
            "placeholder": "​",
            "style": "IPY_MODEL_e40c2bc92ef44f1eb15daf1643cfa95d",
            "value": "Downloading: 100%"
          }
        },
        "dad6e8b4c2a042e89b7c2205d2a81d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b565ecad944faeae9224de84480e95",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4445a17bbe8a4df68ae21504af34f685",
            "value": 1355256
          }
        },
        "b4d929effc8b41d389daf3becac2fa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c21e1191afd43a6941becb6541657e5",
            "placeholder": "​",
            "style": "IPY_MODEL_297b7aa53ed14d9e8f31e411be600fdd",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.85MB/s]"
          }
        },
        "c1af9a634090418f8d0e4c4d5b262fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4a5b5077b1443cb2373f1b9cd85af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40c2bc92ef44f1eb15daf1643cfa95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b565ecad944faeae9224de84480e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4445a17bbe8a4df68ae21504af34f685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c21e1191afd43a6941becb6541657e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297b7aa53ed14d9e8f31e411be600fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb8128631d04a27803200fd83416f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2cde3394347481a9cef02c5a5ebc1db",
              "IPY_MODEL_d0e749ffba7349c1876642bb46b4a8b0",
              "IPY_MODEL_0a80c6ecf0e04e10b3a4b7743713edd6"
            ],
            "layout": "IPY_MODEL_ecd3cde9b87040a08849d19ce2651368"
          }
        },
        "c2cde3394347481a9cef02c5a5ebc1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0f9ae3a0ce42639f88380d7ccd19c4",
            "placeholder": "​",
            "style": "IPY_MODEL_12089b0ffc334b6f9d67b49d8c5a9b7c",
            "value": "Downloading: 100%"
          }
        },
        "d0e749ffba7349c1876642bb46b4a8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f472d698ab4197a0f2c4a7a3994829",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b469307e85e14a629a4a65c67b72f0cb",
            "value": 548118077
          }
        },
        "0a80c6ecf0e04e10b3a4b7743713edd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d460b2f730c4f8d9fa8fd987ac7c542",
            "placeholder": "​",
            "style": "IPY_MODEL_a6ac6c75e5fa4bfd9fa04bc7539a0eb2",
            "value": " 523M/523M [00:15&lt;00:00, 43.2MB/s]"
          }
        },
        "ecd3cde9b87040a08849d19ce2651368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0f9ae3a0ce42639f88380d7ccd19c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12089b0ffc334b6f9d67b49d8c5a9b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f472d698ab4197a0f2c4a7a3994829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b469307e85e14a629a4a65c67b72f0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d460b2f730c4f8d9fa8fd987ac7c542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ac6c75e5fa4bfd9fa04bc7539a0eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLk0deDvEDfi",
        "outputId": "696af46b-c02c-4034-a34f-61da4d66867e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UFM-AI-22'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 83 (delta 36), reused 34 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n",
            "/content/UFM-AI-22\n",
            "⏳ Installing base requirements ...\n",
            "✅ Base requirements installed!\n",
            "⏳ Installing Git LFS ...\n",
            "✅ Git LFS installed!\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/0xpantera/UFM-AI-22.git\n",
        "%cd UFM-AI-22\n",
        "from install import *\n",
        "install_requirements()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation\n",
        "\n",
        "Una de las características más extrañas de los modelos de lenguaje basados en transformers es su capacidad para generar texto que es casi indistinguible de texto escrito por humanos. Un ejemplo famoso es el de GPT-2 de OpenAI, que cuando se le presenta el prompt[1]:\n",
        "\n",
        "> In a shocking finding, scientist discovered a herd of unicorns living in a remote, previ‐ ously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
        "\n",
        "genera un articulo que habla sobre unicornios:\n",
        "\n",
        "> The scientist named the population, after their distinctive horn, Ovid’s Unicorn. These four-horned, silver-white unicorns were previously unknown to science. Now, after almost two centuries, the mystery of what sparked this odd phenomenon is finally solved. Dr. Jorge Pérez, an evolutionary biologist from the University of La Paz, and several companions, were exploring the Andes Mountains when they found a small valley, with no other animals or humans. Pérez noticed that the valley had what appeared to be a natural fountain, surrounded by two peaks of rock and silver snow. Pérez and the others then ventured further into the valley. “By the time we reached the top of one peak, the water looked blue, with some crystals on top,” said Pérez. Pérez and his friends were astonished to see the unicorn herd. These creatures could be seen from the air without having to move too much to see them—they were so close they could touch their horns. While examining these bizarre creatures the scientists discov‐ ered that the creatures also spoke some fairly regular English ...\n",
        "\n",
        "Lo que hace que este ejemplo sea tan notable es que se generó sin ninguna supervisión explícita. Simplemente aprendiendo a predecir la siguiente palabra en el texto de millones de páginas web, GPT-2 y sus descendientes más poderosos como GPT-3 pueden aprender un gran conjunto de habilidades y capacidades de reconocimiento de patrones que se pueden activar con diferentes tipos de prompts. Los modelos de lenguaje a veces se exponen durante el pretraining a secuencias de tareas en las que necesitan predecir los siguientes tokens basándose únicamente en el contexto, como sumas, ordenar palabras desordenadas y traducir. Esto les permite hacer knowledge transfer de manera efectiva durante el finetunning o (si el modelo es lo suficientemente grande) a la hora de hacer inferencia. Estas tareas no se eligen con anticipación, sino que ocurren naturalmente en los enormes corpus utilizados para entrenar modelos de lenguaje de miles de millones de parámetros.\n",
        "\n",
        "La capacidad de los transformers para generar texto realista ha dado lugar a una amplia gama de aplicaciones, como [InferKit](https://app.inferkit.com/demo), [Write With Transformer](https://transformer.huggingface.co/), [AI Dungeon](https://play.aidungeon.io/) y agentes conversacionales como [Meena de Google](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html) que incluso pueden contar chistes cursis[2].\n",
        "\n",
        "En este notebook vamos a usar GPT-2 para ilustrar como la generacion de texto funciona para modelos de lenguajes y explorar como diferentes estrategias de decoding impactan el texto generado.\n",
        "\n",
        "[1] Este ejemplo viene del [blog de OpenAI sobre GPT-2](https://openai.com/blog/better-language-models)\n",
        "\n",
        "[2] Sin embargo, [como indica Delip Rao](https://twitter.com/deliprao/status/1479555633242259456), si Meena _pretende_ contar chistes cursis es una pregunta sutil.\n",
        "\n"
      ],
      "metadata": {
        "id": "lfKHZCBFEZbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasta ahora, en esta clase, nos hemos concentrado en abordar las tareas de NLP a través de una combinación de pretraining y finetunning supervisado. Como hemos visto, para las cabezas específicas a tareas como la clasificación de secuencias o tokens, generar predicciones es bastante sencillo; el modelo produce algunos logits y agarramos el valor máximo para obtener la clase predecida, o aplicamos una función softmax para obtener las probabilidades predecidas por clase. Por otro lado, convertir el output probabilístico del modelo en texto requiere un método de decoding, que tiene algunos desafíos que son exclusivos de la generación de texto:\n",
        "\n",
        "- La decodificación se realiza de forma iterativa y, por lo tanto, implica mucho más cálculo que simplemente pasar los inputs una vez a través del forward pass de un modelo.\n",
        "- La calidad y diversidad del texto generado depende de la elección del método de decodificación y los hiperparámetros asociados.\n",
        "\n",
        "Para comprender cómo funciona este proceso de decodificación, comencemos viendoo cómo se preentrena GPT-2 y cómo se aplica posteriormente para generar texto.\n",
        "\n",
        "Como otros modelos de lenguaje autoregresivos o causales, GPT-2 esta preentrenado para estimar la probabilidad $P(y|x)$ de una secuencia de tokens $y = y_1, y_2, ..., y_t$ que ocurren en un texto, dado un prompt inicial o una secuencia de contexto $x = x_1, x_2, ..., x_k$. Ya que es impractico adquirir suficiente data de entrenamiento para estimar $P(y|x)$ directamente, es comun usar la regla de la cadena de probabilidad para factorizarlo como un producto de probabilidades condicionales:\n",
        "\n",
        "$P(y_1,...,y_t|x) = \\prod^{N}_{t=1} P(y_t|y_{<t}, x)$\n",
        "\n",
        "donde $y_{<t}$ es una notacion corta para la secuencia $y_1,...,y_{t-1}$. Es de estas probabilidades condicionales que agarramos la intuicion que el modelado de lenguaje autoregresivo equivale a predecir cada palabra dada la palabra que la precede en una oracion. Esto es exactamente lo que la probabilidad en el lado derecho de la equacion describe. Noten que este objetivo de preentrenamiento es diferente al de BERT, que usa contexto del pasado y futuro para predecir un token enmascarado.\n",
        "\n",
        "Probablemente ya se dieron cuenta cómo podemos adaptar esta tarea de predicción de tokens para generar secuencias de texto de longitud arbitraria. Comenzamos con un mensaje como \"Los transformers son los\" y usamos el modelo para predecir el siguiente token. Una vez que hemos determinado el siguiente token, lo agregamos al prompt y luego usamos la nueva secuencia de entrada para generar otro token. Hacemos esto hasta que hayamos alcanzado un token especial de fin de secuencia o una longitud máxima predefinida.\n",
        "\n",
        "> Dado que el output de una secuencia esta condicionado sobre la eleccion de input prompt, este tipo de generacion de texto se conoce como _conditional text generation_\n",
        "\n",
        "En el corazón de este proceso hay un método de decodificación que determina qué token se selecciona en cada timestep. Dado que el modelo de lenguaje head produce un logit $z_{t,i}$ por token en el vocabulario en cada paso, podemos obtener la distribución de probabilidad sobre el próximo token $w_i$ tomando el softmax:\n",
        "\n",
        "$P(y_t = w_i | y_{<t}, x) = softmax(z_{t,i})$\n",
        "\n",
        "La meta de la mayoria de metodos de decodificacion es buscar la secuencia general mas probable eligiendo un $ŷ$ de modo que:\n",
        "\n",
        "$ŷ = argmax P(y|x)$\n",
        "\n",
        "Encontrar $ŷ$ directamente involucra evaluar cada posible secuencia con el modelo de lenguaje. Como no existe un algoritmo que pueda hacer esto en un tiempo razonable, nos apoyamos con aproximaciones. Vamos a explorar un par de estar aproximaciones y gradualmente llegar a un algoritmo mas inteligente y complejo que podamos usar para generar texto de alta calidad."
      ],
      "metadata": {
        "id": "XNIje1KFGiIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy Search Decoding\n",
        "\n",
        "El método de decodificación más simple para obtener tokens discretos del output continu de un modelo es seleccionar _greedily_ (con avaricia? 🤷) el token con la mayor probabilidad en cada timestep:\n",
        "\n",
        "$ŷ_t = argmax P(y_t|y_{<t}, x)$\n",
        "\n",
        "Para ver como funciona greedy search, vamos a empezar cargando la version de GPT-2 con 1.5-billones de parametros con una cabeza de modelado de lenguaje:\n",
        "\n",
        "> Si se quedan sin memoria, pueden probar cargar una version mas pequenia, reemplazando `model_name = \"gpt-xl\"` por `\"gpt\"`."
      ],
      "metadata": {
        "id": "zfD2857SLTR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "d39ad6b081a14b05868a011f87819399",
            "8f9b4e18295e4acdb62778d85f8ab9c3",
            "728b096756f042bf98a09d0feef343fe",
            "c74e37d7ef524cd68a5005c6f53e84e5",
            "6a4b4a3d87604c32a0b557dd73b4fc31",
            "aef3752f9cca47d68afc9f061a2b5dda",
            "743fd462a25a4bc2a7bd3572d6d6e58b",
            "ab8e5b06088648d791d48d02b667e849",
            "6b4aaa1e9b0e43f48ccbdb3642f90b45",
            "ac216e9aa2ce4219acf8a91fac050e01",
            "3e2faa7f70cf4dbe910610ee7b216d5e",
            "a40eb2ebcb0347beb81ec289e63d6185",
            "6968962ec55d42df8b893a63206c733c",
            "6d130b10151b44a991debbd23cffd40b",
            "84e8eb32124241b5b3b3a4ec1a07f12e",
            "7ca96234db33425c926eef9ee1284be0",
            "74bcd8f11f1f4eaf9679bb70162d975d",
            "0d5ea266c15545d1b3db5a4fc11e6b68",
            "23ff78bfe2de4363a07d179e1210a52c",
            "8b58cb082e9c47f69c5d19d627273231",
            "e480b02d1eab48c1a6ea3211936fa7a7",
            "9a0457a7fb354f008ad51ca388e9e4f2",
            "c83ed795fcba4016a54297088d67ee6a",
            "fb0564ae7eb6436381f83e2461fdc02b",
            "99c11a811f7f498885f00745fbc10bdb",
            "cb4eb3618ab24acdb0d7f9507deb6744",
            "4e13b57a0c374c3da782df32e92d62f9",
            "6c17192ffa56407c9bf2eb43612c3c3b",
            "eef8ceed7f5140deace8a302cc704a68",
            "8f5b6fb4aaac46008627390c01221bd0",
            "6669588ba4eb484da1e952f503e98ba4",
            "9616f3c02e1b405baf570227acd63c94",
            "5c43c5011672449da95099d0ee961123",
            "f244838b19a249c494ae443a4f147491",
            "cfb7ae726d324c978990368734de4a0b",
            "dad6e8b4c2a042e89b7c2205d2a81d0f",
            "b4d929effc8b41d389daf3becac2fa90",
            "c1af9a634090418f8d0e4c4d5b262fb2",
            "dc4a5b5077b1443cb2373f1b9cd85af6",
            "e40c2bc92ef44f1eb15daf1643cfa95d",
            "70b565ecad944faeae9224de84480e95",
            "4445a17bbe8a4df68ae21504af34f685",
            "8c21e1191afd43a6941becb6541657e5",
            "297b7aa53ed14d9e8f31e411be600fdd",
            "bbb8128631d04a27803200fd83416f77",
            "c2cde3394347481a9cef02c5a5ebc1db",
            "d0e749ffba7349c1876642bb46b4a8b0",
            "0a80c6ecf0e04e10b3a4b7743713edd6",
            "ecd3cde9b87040a08849d19ce2651368",
            "0f0f9ae3a0ce42639f88380d7ccd19c4",
            "12089b0ffc334b6f9d67b49d8c5a9b7c",
            "20f472d698ab4197a0f2c4a7a3994829",
            "b469307e85e14a629a4a65c67b72f0cb",
            "6d460b2f730c4f8d9fa8fd987ac7c542",
            "a6ac6c75e5fa4bfd9fa04bc7539a0eb2"
          ]
        },
        "id": "2LfNii6tEKux",
        "outputId": "1d9abd79-8ae9-4017-df17-29baeba2512b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d39ad6b081a14b05868a011f87819399"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a40eb2ebcb0347beb81ec289e63d6185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c83ed795fcba4016a54297088d67ee6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f244838b19a249c494ae443a4f147491"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbb8128631d04a27803200fd83416f77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora generemos un poco de texto. Aunque 🤗 Transformers provee una function `generate()` para modelos autoregresivos como GPT-2, vamos a implementar este metodo de decoding nosotros para ver como funciona. \n",
        "\n",
        "Para calentar, vamos a tomar un enfoque iterativo: usar \"Transformers are the\" como input prompt y ejecutar la decodificación durante ocho timesteps. En cada timestep, seleccionamos los logits del modelo para el último token en el prompt y los ajustamos con un softmax para obtener una distribución de probabilidad. Luego, elegimos el siguiente token con la probabilidad más alta, lo agregamos a la secuencia de entrada y ejecutamos el proceso nuevamente. El siguiente código hace el trabajo y también almacena los cinco tokens más probables en cada paso de tiempo para que podamos visualizar las alternativas:"
      ],
      "metadata": {
        "id": "avaZNqULMLq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "input_txt = \"Transformers are the\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "iterations = []\n",
        "n_steps = 8\n",
        "choices_per_step = 5\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(n_steps):\n",
        "        iteration = dict()\n",
        "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
        "        output = model(input_ids=input_ids)\n",
        "        # Select logits of the first batch and the last token and apply softmax \n",
        "        next_token_logits = output.logits[0, -1, :]\n",
        "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
        "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True) \n",
        "        # Store tokens with highest probabilities\n",
        "        for choice_idx in range(choices_per_step):\n",
        "            token_id = sorted_ids[choice_idx]\n",
        "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
        "            token_choice = (\n",
        "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
        "            )\n",
        "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
        "        # Append predicted next token to input\n",
        "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
        "        iterations.append(iteration)\n",
        "pd.DataFrame(iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "g6z_V82GL-nG",
        "outputId": "96b4460f-fb87-47bf-dcdd-336e3725cc61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Input           Choice 1  \\\n",
              "0                               Transformers are the       most (9.76%)   \n",
              "1                          Transformers are the most    common (22.90%)   \n",
              "2                   Transformers are the most common      type (15.06%)   \n",
              "3              Transformers are the most common type        of (83.13%)   \n",
              "4           Transformers are the most common type of   particle (1.55%)   \n",
              "5  Transformers are the most common type of particle         . (14.26%)   \n",
              "6  Transformers are the most common type of parti...      They (17.48%)   \n",
              "7  Transformers are the most common type of parti...       are (38.78%)   \n",
              "\n",
              "            Choice 2            Choice 3          Choice 4  \\\n",
              "0       same (2.94%)        only (2.87%)      best (2.38%)   \n",
              "1   powerful (6.88%)   important (6.32%)   popular (3.95%)   \n",
              "2      types (3.31%)        form (1.91%)       way (1.89%)   \n",
              "3         in (3.16%)           . (1.92%)         , (1.63%)   \n",
              "4     object (1.02%)       light (0.71%)    energy (0.67%)   \n",
              "5        in (11.57%)       that (10.19%)         , (9.57%)   \n",
              "6        \\n (15.19%)         The (7.06%)     These (3.09%)   \n",
              "7       have (8.14%)         can (7.99%)       're (5.04%)   \n",
              "\n",
              "               Choice 5  \n",
              "0         first (1.77%)  \n",
              "1      commonly (2.14%)  \n",
              "2           and (1.49%)  \n",
              "3           for (0.88%)  \n",
              "4       objects (0.66%)  \n",
              "5   accelerator (5.81%)  \n",
              "6            In (3.07%)  \n",
              "7       consist (1.57%)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-449fefe5-75a8-4703-afb3-a9a21eeb3d28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Choice 1</th>\n",
              "      <th>Choice 2</th>\n",
              "      <th>Choice 3</th>\n",
              "      <th>Choice 4</th>\n",
              "      <th>Choice 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transformers are the</td>\n",
              "      <td>most (9.76%)</td>\n",
              "      <td>same (2.94%)</td>\n",
              "      <td>only (2.87%)</td>\n",
              "      <td>best (2.38%)</td>\n",
              "      <td>first (1.77%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformers are the most</td>\n",
              "      <td>common (22.90%)</td>\n",
              "      <td>powerful (6.88%)</td>\n",
              "      <td>important (6.32%)</td>\n",
              "      <td>popular (3.95%)</td>\n",
              "      <td>commonly (2.14%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transformers are the most common</td>\n",
              "      <td>type (15.06%)</td>\n",
              "      <td>types (3.31%)</td>\n",
              "      <td>form (1.91%)</td>\n",
              "      <td>way (1.89%)</td>\n",
              "      <td>and (1.49%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Transformers are the most common type</td>\n",
              "      <td>of (83.13%)</td>\n",
              "      <td>in (3.16%)</td>\n",
              "      <td>. (1.92%)</td>\n",
              "      <td>, (1.63%)</td>\n",
              "      <td>for (0.88%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transformers are the most common type of</td>\n",
              "      <td>particle (1.55%)</td>\n",
              "      <td>object (1.02%)</td>\n",
              "      <td>light (0.71%)</td>\n",
              "      <td>energy (0.67%)</td>\n",
              "      <td>objects (0.66%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Transformers are the most common type of particle</td>\n",
              "      <td>. (14.26%)</td>\n",
              "      <td>in (11.57%)</td>\n",
              "      <td>that (10.19%)</td>\n",
              "      <td>, (9.57%)</td>\n",
              "      <td>accelerator (5.81%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Transformers are the most common type of parti...</td>\n",
              "      <td>They (17.48%)</td>\n",
              "      <td>\\n (15.19%)</td>\n",
              "      <td>The (7.06%)</td>\n",
              "      <td>These (3.09%)</td>\n",
              "      <td>In (3.07%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Transformers are the most common type of parti...</td>\n",
              "      <td>are (38.78%)</td>\n",
              "      <td>have (8.14%)</td>\n",
              "      <td>can (7.99%)</td>\n",
              "      <td>'re (5.04%)</td>\n",
              "      <td>consist (1.57%)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-449fefe5-75a8-4703-afb3-a9a21eeb3d28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-449fefe5-75a8-4703-afb3-a9a21eeb3d28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-449fefe5-75a8-4703-afb3-a9a21eeb3d28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con este método simple pudimos generar la frase “Transformers are the most popular toy line in the world” (este fue el output de \"gpt2-xl\" pero este modelo hace que colab crashee. El \"gpt\" pequenio nos da un output mas malo). Curiosamente, esto indica que GPT-2 ha internalizado algunos conocimientos sobre la franquicia de Transformers, que fue creada por dos empresas de juguetes (Hasbro y Takara Tomy). También podemos ver las otras posibles continuaciones en cada paso, lo que muestra la naturaleza iterativa de la generación de texto. A diferencia de otras tareas, como la clasificación de secuencias, donde es suficiente con un solo forward pass para generar las predicciones, con la generación de texto necesitamos decodificar los tokens de salida uno a la vez.\n",
        "\n",
        "Implementar greedy search no fue demasiado difícil, pero queremos usar la función `generar()` integrada de Transformers para explorar métodos de decodificación más sofisticados. Para reproducir nuestro ejemplo simple, asegurémonos de que el sampling esté desactivado (está desactivado de forma predeterminada, a menos que la configuración específica del modelo desde el que está cargando el checkpoint diga lo contrario) y especifiquemos `max_new_tokens` para la cantidad de tokens recién generados:"
      ],
      "metadata": {
        "id": "4M3qhrZhNZXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device) \n",
        "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False) \n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ePtsFiNTOq",
        "outputId": "b27149e2-4a3d-4b0a-b4c4-c3d5b81e18b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers are the most common type of particle. They are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora provemos algo mas interesante: podemos reproducir la historia de unicornios de OpenAI? Vamos a especificar un `max_length` mas grande para generar secuencias mas largas de texto:"
      ],
      "metadata": {
        "id": "ZSdSkcgfOh8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
        "a herd of unicorns living in a remote, previously unexplored \\\n",
        "valley, in the Andes Mountains. Even more surprising to the \\\n",
        "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
        "\"\"\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device) \n",
        "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False) \n",
        "print(tokenizer.decode(output_greedy[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSyorPGQOfYQ",
        "outputId": "3eeaea3e-2a2d-4851-b2e7-8eaed73aafe5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copio el output de \"gp2-xl\" que es mejor:\n",
        "\n",
        "> In a shocking finding, scientist discovered a herd of unicorns living in a\n",
        "    remote, previously unexplored valley, in the Andes Mountains. Even more\n",
        "    surprising to the researchers was the fact that the unicorns spoke perfect\n",
        "    English.\n",
        "The researchers, from the University of California, Davis, and the University of\n",
        "    Colorado, Boulder, were conducting a study on the Andean cloud forest, which is\n",
        "    home to the rare species of cloud forest trees.\n",
        "    The researchers were surprised to find that the unicorns were able to\n",
        "    communicate with each other, and even with humans.\n",
        "    The researchers were surprised to find that the unicorns were able\n",
        "\n",
        "\n",
        "Bueno, las primeras oraciones son bastante diferentes del ejemplo de OpenAI e involucran a diferentes universidades a las que se les atribuye el descubrimiento. También podemos ver uno de los principales inconvenientes de la decodificación de greedy search: tiende a producir secuencias de output repetitivas, lo que fijo no es deseable en un artículo de noticias. Este es un problema común con los algoritmos de búsqueda _greedy_, que pueden fallar en darnos la solución óptima; en el contexto de la decodificación, pueden pasar por alto secuencias de palabras cuya probabilidad general es mayor simplemente porque las palabras de alta probabilidad están precedidas por otras de baja probabilidad.\n",
        "Afortunadamente, podemos hacerlo mejor: examinemos un método popular conocido como _beam search decoding_.\n",
        "\n",
        "> Aunque la decodificación de greedy search rara vez se usa para tareas de generación de texto que requieren diversidad, puede ser útil para producir secuencias cortas como aritmética donde se prefiere un output deterministico y objetivamente correcto.[3] Para estas tareas, pueden condicionar GPT-2 proporcionando algunos ejemplos separados por líneas en el formato \"5 + 8 => 13 \\n 7 + 2 => 9 \\n 1 + 0 =>\" como input prompt.\n",
        "\n",
        "[3] N.S. Keskar et al., [“CTRL: A Conditional Transformer Language Model for Controllable Generation”](https://arxiv.org/abs/1909.05858), (2019)."
      ],
      "metadata": {
        "id": "p_SudOrGO6qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam Search Decoding\n",
        "\n",
        "En lugar de decodificar el token con la probabilidad más alta en cada paso, beam search lleva un registro de los top-_b_ tokens mas probables, donde _b_ se conoce como el número de _beams_ o hipótesis parciales. El siguiente conjunto de beams se elige considerando todas las posibles extensiones del siguiente token del conjunto existente y seleccionando las b extensiones más probables. El proceso se repite hasta que alcanzamos la longitud máxima o un token EOS, y la secuencia más probable se selecciona clasificando los beams b según sus probabilidades logarítmicas.\n",
        "\n",
        "Porque calificamos las secuencias usando probabilidades logartimicas en vez de probabilidades? Una razon es que calcular la probabilidad de una secuencia $P(y_1,...,y_t|x)$ involucra calcular un producto de probabilidades condicionales $P(y_t|y_{<t},x)$. Como cada probabilidad condicional es normalmente un numero pequenio en el rango [0,1], tomar sus productos puede llevarnos a una probabilidad que cause un underflow. Esto significa que la computadora ya no puede representar precisamente el resultado de los calculos. Por ejemplo, supongamos que tenemos una secuencia de $t = 1024$ tokens y asumamos que la probabilidad de cada token es 0.5. La probabilidad de la secuencia es un numero extremadamente pequenio:"
      ],
      "metadata": {
        "id": "XZ9YeFu1ZG0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0.5 ** 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU2kMdi4Ozlp",
        "outputId": "0ae70981-26fc-40dc-8cb4-7cdb13167cf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.562684646268003e-309"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lo cual nos lleva a inestabilidad numerica cuando llegamos al underflow. Podemos evitar esto calculando un termino relacionado, la probabilidad logartimica. Si aplicamos el logaritmos a la probabilidad conjunta y condicional, con la ayuda de la regla de productos para logaritmos obtenemos:\n",
        "\n",
        "$log P(y_1,...,y_t|x) = \\sum^N_{t=1} log P(y_t|y_{<t}, x)$\n",
        "\n",
        "En otras palabras, el producto de las probabilidades que vimos antes se vuelve una suma de probabilidades logartimicas, lo cual nos evita inestabilidad numerica. Por ejemplo, calcular la probabilidad logaritmica del mismo ejemplo nos da:"
      ],
      "metadata": {
        "id": "V3YXlArOavxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sum([np.log(0.5)] * 1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8axZCoRauiY",
        "outputId": "a59be7d4-3602-4d5e-9304-e787a315f142"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-709.7827128933695"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este es un número con el que podemos lidiar fácilmente, y este enfoque aún funciona para números mucho más pequeños. Como solo queremos comparar probabilidades relativas, podemos hacerlo directamente con probabilidades logarítmicas.\n",
        "\n",
        "Calculemos y comparemos las probabilidades logarítmicas de los textos generados por greedy search y por beam search para ver si beam search puede mejorar la probabilidad general. Dado que los modelos de 🤗 Transformers devuelven los logits no normalizados para el siguiente token dados los tokens de entrada, primero debemos normalizar los logits para crear una distribución de probabilidad sobre todo el vocabulario para cada token en la secuencia. Luego, debemos seleccionar solo las probabilidades de tokens que estaban presentes en la secuencia. La siguiente función implementa estos pasos:"
      ],
      "metadata": {
        "id": "JY4kP69JbqXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def log_probs_from_logits(logits, labels):\n",
        "    logp = F.log_softmax(logits, dim=-1)\n",
        "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1) \n",
        "    return logp_label"
      ],
      "metadata": {
        "id": "aAFH0nvybkFG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos da la probabilidad logarítmica de un solo token, por lo que para obtener la probabilidad logarítmica total de una secuencia solo necesitamos sumar las probabilidades logarítmicas de cada token:"
      ],
      "metadata": {
        "id": "IfTluT3-cHQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_logprob(model, labels, input_len=0): \n",
        "    with torch.no_grad():\n",
        "        output = model(labels)\n",
        "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], labels[:, 1:])\n",
        "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
        "    return seq_log_prob.cpu().numpy()"
      ],
      "metadata": {
        "id": "vV3nkoEgcEem"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tengan en cuenta que ignoramos las probabilidades logarítmicas de la secuencia de input porque el modelo no las genera. También podemos ver que es importante alinear los logits y las etiquetas; dado que el modelo predice el siguiente token, no obtenemos un logit para la primera etiqueta y no necesitamos el último logit porque no tenemos un token de verdad (ground truth) para él.\n",
        "\n",
        "Usemos estas funciones para calcular primero la probabilidad logaritmica de la secuencia del greedy search decoder en el prompt de OpenAI:"
      ],
      "metadata": {
        "id": "jNfOy6f1cbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0])) \n",
        "print(tokenizer.decode(output_greedy[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cnBgtOwcYRM",
        "outputId": "42dc9664-7aa5-4aa2-e9a5-51eb11bc79fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n",
            "\n",
            "log-prob: -83.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora comparemos esto con una secuencia que se genera con beam search. Para activar beam search con la función `generate()` solo necesitamos especificar el número de beams con el parámetro `num_beams`. Cuantos más beams elijamos, mejor será potencialmente el resultado; sin embargo, el proceso de generación se vuelve mucho más lento ya que generamos secuencias paralelas para cada beam:"
      ],
      "metadata": {
        "id": "rdsyPoTnc6Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
        "                             do_sample=False)\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0])) \n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQuc5gV6c1Wb",
        "outputId": "c1eb941c-c819-479a-cb76-720c69401b9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "The researchers, from the University of California, San Diego, and the University of California, Santa Cruz, found that the unicorns were able to communicate with each other in a way that was similar to that of human speech.\n",
            "\n",
            "\n",
            "\"The unicorns were able to communicate with each other in a way that was similar to that of human speech,\" said study co-lead author Dr. David J.\n",
            "\n",
            "log-prob: -78.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que obtenemos una mejor probabilidad logaritmica (más alta es mejor) con beam search que con greedy decoding. Sin embargo, podemos ver que beam search también sufre de texto repetitivo. Una forma de abordar esto es imponer una penalización de n-gram con el parámetro `no_repeat_ngram_size` que rastrea qué n-grams se han visto y pone la probabilidad del siguiente token en cero si produce un n-gram visto anteriormente:"
      ],
      "metadata": {
        "id": "gedg0yTBdmWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
        "                             do_sample=False, no_repeat_ngram_size=2)\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0])) \n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogAi9YtxdhH3",
        "outputId": "848bc14b-48b4-454f-f3ac-63ed66316513"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "The researchers, from the University of California, San Diego, and the National Science Foundation (NSF) in Boulder, Colorado, were able to translate the words of the unicorn into English, which they then translated into Spanish.\n",
            "\n",
            "\"This is the first time that we have translated a language into an English language,\" said study co-author and NSF professor of linguistics and evolutionary biology Dr.\n",
            "\n",
            "log-prob: -101.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos logrado detener las repeticiones y podemos ver que a pesar de producir una puntuación más baja, el texto sigue siendo coherente. Beam search con penalización de n-grams es una buena manera de encontrar un equilibrio entre centrarse en tokens de alta probabilidad (con beam search) y reducir las repeticiones (con penalización de n-grams), y se usa comúnmente en aplicaciones como resúmenes o traducción automática donde la exactitud de los hechos es importante. Cuando la exactitud de los hechos es menos importante que la diversidad de los resultados generados, por ejemplo, en una conversacion de dominio abierto o en la generación de historias, otra alternativa para reducir las repeticiones y mejorar la diversidad es usar el muestreo.\n",
        "\n",
        "## Metodos de Muestro\n",
        "\n",
        "El metodo de muestreo mas simple es muestrear aleatoriamente de la distribucion de probabilidades del output del modelo sobre todo el vocabulario en cada timestep:\n",
        "\n",
        "$P(y_t = w_i|y_{<t}, x) = softmax(z_{t,i}) = \\frac{exp(z_{t,i})}{\\sum^{|V|}_{j=1}exp(z_{t,j})})$\n",
        "\n",
        "donde $|V|$ denota la cardinalidad del vocabulario. Podemos controlar la diversidad del output facilmente aniadiendo un parametro de temperatrua $T$ que reescala los logits antes de aplicar softmax:\n",
        "\n",
        "$P(y_t = w_i|y_{<t}, x) = softmax(z_{t,i}/T) = \\frac{exp(z_{t,i})}{\\sum^{|V|}_{j=1}exp(z_{t,j}/T)})$\n",
        "\n",
        "Al modificar $T$ podemos controlar la forma de la distribucion de probabilidiades[4]. Cuando $T << 1$, la distribucion tiene un pico al rededor del origen y se suprimen las tokens raras. Por otro lado, cuando $T >> 1$, la distribucion se aplana y cada token se vuelve igual de probable. \n",
        "\n",
        "Para ver como se puede usar la temperatura para influenciar el texto generado, podemos muestrear con `T = 2` usando el parametro `temperature` en la funcion `generate()` (luego explico el significado de `top_k`):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[4] Si lo vieron en clases de fisica, podran reconocer el parecida a una [distribucion de Boltzmann](https://en.wikipedia.org/wiki/Boltzmann_distribution)"
      ],
      "metadata": {
        "id": "O8wuvYuPeVbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             temperature=2.0, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "id": "kCTC7upCeFLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e338665-5d76-4553-b9e7-d99b7b318dba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "Israel Websterisch Rowlinghorn inside GallupThirtyWin I Have as role dependentitiz corpses club ardu horribly inclino horse legit sweep atop AbsPi staffethe Stew und famously articlesstyle extending leg costumesHEcompany mer releases ce aliasesles healthcareilling rockedsub canopygrim SexForge Valhalla owes recordsplanes inspiringir suchHO wrestlersleader Mmosilini fulf000978hib natops clausezagazingnatal RecognEm Pug put heirs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que una temperatura alta produce basura; al acentuar los tokens raros, hacemos que el modelo cree una gramatica rara y con bastantes palabras inventadas. Veamos que pasa si bajamos la temperatura:"
      ],
      "metadata": {
        "id": "F5g-vXRJHOOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             temperature=0.5, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V3KAWzeHHHM",
        "outputId": "dd5f1ad0-fac7-4555-d660-c1af017a074c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "The unicorns lived in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. The unicorns were found to have a \"sensitivity to language,\" according to the report.\n",
            "\n",
            "\n",
            "\"The unicorns were able to speak the language of their native tongue, which is common among humans,\" said lead author\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto es significativamente mas coherente y hasta incluye una cita de otra universidad a la que se le atribuye el descubrimiento (en la version de `gp2-xl` que incluyo abajo). La leccion principal que podemos sacar de la temperatura es que nos permite controlar la calidad de las muestras, pero siempre hay un equilibrio entre la coherencia (baja temperatura) y la diversidad (alta temperatura) que uno tiene que ajustar al usar.\n",
        "\n",
        "Otra forma de ajustar el trade-off entre coherencia y diversidad es truncar la distribución del vocabulario. Esto nos permite ajustar la diversidad libremente con la temperatura, pero en un rango mas limitado que excluye palabras que serian demasiado extranias en el contexto (es decir, palabras de baja probabilidad). Hay dos formas principales de hacer esto: top-k y nucleus (o top-p) sampling.\n",
        "\n",
        "Output de `gpt2-xl`:\n",
        "\n",
        "> In a shocking finding, scientist discovered a herd of unicorns living in a\n",
        "    remote, previously unexplored valley, in the Andes Mountains. Even more\n",
        "    surprising to the researchers was the fact that the unicorns spoke perfect\n",
        "    English.\n",
        "    The scientists were searching for the source of the mysterious sound, which was\n",
        "    making the animals laugh and cry.\n",
        "    The unicorns were living in a remote valley in the Andes mountains\n",
        "    'When we first heard the noise of the animals, we thought it was a lion or a\n",
        "    tiger,' said Luis Guzman, a researcher from the University of Buenos Aires,\n",
        "    Argentina.\n",
        "'But when\n",
        "\n",
        "\n",
        "## Top-k y Nucleus Sampling\n",
        "\n",
        "El muestreo Top-k y nucleus (top-p) son dos alternativas populares o extensiones para usar temperatura. En ambos casos, la idea basica es restringir la cantidad de tokens posibles de los que podemos muestrear en cada timestep. Para ver como funciona esto, primero visualicemos la distribucion de probabilidades cumulativas de los outputs del modelo en $T = 1$ como se ve en la grafica.\n",
        "\n",
        "[GRAFICA]\n",
        "\n",
        "El plot superior nos muestra el histograma de las probabilidades de los tokens. Tiene un pico alrededor de $10^{-18}$ y un segundo pico mas pequenio alrededor de $10^{-4}$ seguido de una caida precipitada con solo un par de tokens ocurriendo con probabilidad entre $10^{-2}$ y $10^{-1}$. En este plot podemos ver que la probabilidad de escoger el token con la probabilidad mas alta (la barra aislada en $10^{-1}$ es 1 en 10.\n",
        "\n",
        "En el plot inferior, ordenamos los tokens por orden descendiente de probabilidad y calculamos la suma cumulativa de los primeros 10,000 tokens (en total, hay 50,257 tokens en el vocabulario de GPT-2). La linea curva representa la probabilidad de escoger cualquiera de los tokens anteriores. Por ejemplo, hay una chance de ~96% de escoger cualquiera de los 1,000 tokens con probabilidad mas alta. Podemos ver que la probabilidad sube rapidamente arriba de 90% pero se satura cerca de 100% despues de varios miles de tokens. El plot demuestra que hay un chance de 1 en 100 de no escoger cualquiera de los tokens que no estan en los top 2,000.\n",
        "\n",
        "Aunque estos numeros pueden parecer pequeños a primera vista, se vuelven importantes porque muestreamos una vez por token cuando generamos texto. Entonces, incluso si solo hay una probabilidad de 1 en 100 o 1,000, si muestreamos cientos de veces, existe una posibilidad significativa de elegir un token poco probable en algún momento, y elegir estos tokens al muestrear puede influir negativamente en la calidad del texto generado. Por esta razón, generalmente queremos evitar estos tokens muy poco probables. Aquí es donde entran en juego los muestreos top-k y top-p.\n",
        "\n",
        "La idea detrás del muestreo top-k es evitar las opciones de baja probabilidad mediante el muestreo solo de los k tokens con la probabilidad más alta. Esto pone un corte fijo en la cola larga de la distribución y asegura que solo tomamos muestras de opciones probables. Volviendo a la grafica, el muestreo top-k es equivalente a definir una línea vertical y muestrear a partir de las fichas de la izquierda. Una vez más, la función `generate()` proporciona un método fácil para lograr esto con el argumento `top_k`:"
      ],
      "metadata": {
        "id": "xrBcsEJlHv52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             top_k=50)\n",
        "print(tokenizer.decode(output_topk[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C89Gdq4zHm6B",
        "outputId": "55ffb778-ae03-4e64-bd78-f0f5064a1c73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "The researchers claimed that this \"unicorn was found to possess a high level of intelligence in his or her conversation with an unknown companion. This is a result of the presence of transcranial direct current stimulation and transcranial transcranial magnetic stimulation in the brains of primates.\"\n",
            "\n",
            "\n",
            "They found that the animals spoke a language similar to the language spoken by one or both of the unicorns. Furthermore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es el texto mas humano que hemos generado hasta ahora (copio el output de `gpt2-xl` abajo). Pero, como elegimos k? El valor de k se elige manualmente y es el mismo para cada opcion de la secuencia, independientemente de la distribucion de output real. Podemos encontrar un buen valor para k observando algunas metricas de calidad del texto (las vamos a ver mas adelante).\n",
        "\n",
        "Una alternativa es utilizar un corte dinámico. Con muestreo nucleus o top-p, en lugar de elegir un valor de corte fijo, establecemos una condicion de cuando cortar. Esta condicion es cuando se alcanza cierta masa de probabilidad en la seleccion. Digamos que establecemos ese valor en 95%. Luego ordenamos todas las fichas en orden descendente por probabilidad y agregamos una ficha tras otra desde la parte superior de la lista hasta que la suma de las probabilidades de las fichas seleccionadas sea del 95%. Volviendo a la grafica, el valor de p define una linea horizontal en la grafica de la suma acumulada de probabilidades, y solo tomamos muestras de las fichas debajo de la línea. Dependiendo de la distribucion de output, esto podria ser solo un token (muy probable) o cien tokens (igualmente probables). La función `generate()` tambien proporciona un argumento para activar el muestreo `top-p`. Probemos:\n",
        "\n",
        "Output GPT2-XL:\n",
        "> In a shocking finding, scientist discovered a herd of unicorns living in a\n",
        "    remote, previously unexplored valley, in the Andes Mountains. Even more\n",
        "    surprising to the researchers was the fact that the unicorns spoke perfect\n",
        "    English.\n",
        "    The wild unicorns roam the Andes Mountains in the region of Cajamarca, on the\n",
        "    border with Argentina (Picture: Alamy/Ecole Nationale Supérieure d'Histoire\n",
        "    Naturelle)\n",
        "    The researchers came across about 50 of the animals in the valley. They had\n",
        "    lived in such a remote and isolated area at that location for nearly a thousand\n",
        "    years that"
      ],
      "metadata": {
        "id": "vHet2AekRLEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             top_p=0.90)\n",
        "print(tokenizer.decode(output_topp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io52qydWRDnh",
        "outputId": "62069618-f617-4445-ff22-e53f1a89ee18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
            "\n",
            "\n",
            "\"They all were very happy to learn from each other,\" said the professor, who spoke to Science from the University of Colorado's School of English. \"In fact, they were pretty happy they found out about the fact that there's a 'unicorn' living in the valley.\"\n",
            "\n",
            "\n",
            "Researchers used their knowledge to track the unicorn from a series of observations across South America. They were able to identify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El muestreo Top-p tambien ha producido una historia coherente, y esta vez con un nuevo giro sobre las migraciones de Australia a America del Sur (copio el output de gpt2-xl abajo). Incluso podemos combinar los dos enfoques de muestreo para obtener lo mejor de ambos mundos. Establecer `top_k=50` y `top_p=0.9` corresponde a la regla de elegir tokens con una masa de probabilidad del 90%, de un grupo de 50 tokens como maximo.\n",
        "\n",
        "Tambien podemos aplicar beam search cuando usamos sampling. En vez de seleccionar el siguiente batch de tokens candidatos de forma greedy, podemos muestrearlos y construir los beams de la misma forma.\n",
        "\n",
        "Output de GPT2-xl:\n",
        "> In a shocking finding, scientist discovered a herd of unicorns living in a\n",
        "    remote, previously unexplored valley, in the Andes Mountains. Even more\n",
        "    surprising to the researchers was the fact that the unicorns spoke perfect\n",
        "    English.\n",
        "    The scientists studied the DNA of the animals and came to the conclusion that\n",
        "    the herd are descendants of a prehistoric herd that lived in Argentina about\n",
        "    50,000 years ago.\n",
        "    According to the scientific analysis, the first humans who migrated to South\n",
        "    America migrated into the Andes Mountains from South Africa and Australia, after\n",
        "    the last ice age had ended.\n",
        "    Since their migration, the animals have been adapting to"
      ],
      "metadata": {
        "id": "6vl-MbbrSYZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Que metodo de decoding es mejor?\n",
        "\n",
        "Desafortunadamente, no existe un metodo de decoding universalmente \"mejor\". El mejor enfoque depende de la tarea para la que estn generando texto. Si quieren que su modelo realice una tarea precisa como aritmetica o proporcione una respuesta a una pregunta especifica, tienen que reducir la temperatura o utilizar metodos deterministas como greedy search en combinacion con beam search para garantizar la respuesta mas probable. Si quieren que el modelo genere textos mas largos e incluso que sea un poco creativo, tienen que cambiar a metodos de muestreo y aumentar la temperatura o usar una combinacion de muestreo de nucleus y top-k."
      ],
      "metadata": {
        "id": "IW071LFpS6J9"
      }
    }
  ]
}